# FlowScale Environment Configuration
# Copy this file to .env and fill in your values

# ===========================================
# REQUIRED - Backend Configuration
# ===========================================

# Supabase/Lovable Cloud Configuration
# If using Lovable Cloud, these are auto-configured
VITE_SUPABASE_URL=https://your-project.supabase.co
VITE_SUPABASE_PUBLISHABLE_KEY=your-anon-key
VITE_SUPABASE_PROJECT_ID=your-project-id

# ===========================================
# OPTIONAL - Backend Provider Selection
# ===========================================

# Backend provider: supabase (default), rest, local
VITE_BACKEND_PROVIDER=supabase

# REST API URL (only if using rest provider)
VITE_REST_API_URL=http://localhost:3000/api

# n8n Global Webhook URL (optional)
VITE_N8N_WEBHOOK_URL=https://your-n8n.app.n8n.cloud/webhook/flowscale

# ===========================================
# OPTIONAL - AI Provider Configuration
# ===========================================

# AI provider: lovable (default), openai, gemini, ollama, custom
VITE_AI_PROVIDER=lovable

# OpenAI API URL (only if using openai provider directly)
VITE_OPENAI_API_URL=https://api.openai.com/v1

# Gemini API URL (only if using gemini provider directly)
VITE_GEMINI_API_URL=https://generativelanguage.googleapis.com/v1beta

# Ollama URL (for self-hosted LLMs)
VITE_OLLAMA_URL=http://localhost:11434

# Custom AI API URL (for custom endpoints)
VITE_CUSTOM_AI_API_URL=

# ===========================================
# OPTIONAL - Feature Flags
# ===========================================

# Enable local/demo mode (uses localStorage instead of backend)
VITE_ENABLE_LOCAL_MODE=false

# Enable mock data for development
VITE_ENABLE_MOCK_DATA=false

# Enable debug logging
VITE_DEBUG=false

# Docker mode flag
VITE_DOCKER_MODE=false

# ===========================================
# OPTIONAL - Self-Hosting Database
# ===========================================

# PostgreSQL connection (for self-hosted deployments)
# DATABASE_URL=postgresql://user:password@localhost:5432/flowscale

# ===========================================
# NOTES
# ===========================================
# 
# For Lovable Cloud deployments:
# - VITE_SUPABASE_* variables are auto-configured
# - AI uses Lovable AI Gateway (no API key needed)
# - Edge functions deploy automatically
#
# For Self-Hosted deployments:
# - Configure your own Supabase project OR use REST backend
# - Set up your own AI provider (OpenAI, Gemini, or Ollama)
# - Deploy edge functions manually or use Docker
#
# For Docker deployments:
# - Use docker-compose.yml for easy setup
# - All services run locally
# - Set VITE_DOCKER_MODE=true
